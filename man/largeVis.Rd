% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/largeVis.R
\name{largeVis}
\alias{largeVis}
\title{Apply the LargeVis algorithm for visualizing large high-dimensional datasets.}
\usage{
largeVis(x, dim = 2, K = 40, check.assumptions = TRUE, pca.first = TRUE,
  pca.dims = 50, n.trees = 50, tree.threshold = max(10, if (pca.first) {  
    pca.dims } else {     ncol(x) }), max.iter = 3, perplexity = 50,
  sgd.batches = nrow(x) * 20000, M = 5, weight.pos.samples = TRUE,
  alpha = 2, gamma = 7, rho = 1, min.rho = 0, coords = NULL,
  verbose = TRUE, ...)
}
\arguments{
\item{x}{A matrix. Ideally, the columns should be scaled and normalized to avoid the risk of errors caused by overflow.}

\item{dim}{The number of dimensions in the output}

\item{K}{The number of nearest-neighbors to use in computing the kNN graph}

\item{check.assumptions}{Whether to check the input matrix for duplicates, \code{NA}`s, etc.}

\item{pca.first}{Whether to apply pca first (can speed-up distance calculations)}

\item{pca.dims}{How many pca dimensions to use}

\item{n.trees}{See \code{\link{randomProjectionTreeSearch}}.  The default is set at 50, which is the number
used in the examples in the original paper.}

\item{tree.threshold}{See \code{\link{randomProjectionTreeSearch}}.  By default, this is the number of features
in the input set, which is the setting used in the examples in the original paper.  Note the time and memory requirements:
the first pass through the neighborhood exploration phases will involve up to \eqn{N * nTrees * threshold} comparisons.}

\item{max.iter}{See \code{\link{randomProjectionTreeSearch}}.}

\item{perplexity}{See paper}

\item{sgd.batches}{See \code{\link{projectKNNs}}.}

\item{M}{See \code{\link{projectKNNs}}.}

\item{weight.pos.samples}{See \code{\link{projectKNNs}}.}

\item{alpha}{See \code{\link{projectKNNs}}.}

\item{gamma}{See \code{\link{projectKNNs}}.}

\item{coords}{A [N,K] matrix of coordinates to use as a starting point -- useful for refining an embedding in stages.}

\item{verbose}{Verbosity}

\item{...}{See paper}
}
\value{
A `largeVis` object with the following slots:
 \itemize{
   \item{'knns'} {An [N,K] integer matrix, which is an adjacency list of each vertex' identified nearest neighbors.
   If the algorithm failed to find \code{K} neighbors, the matrix is padded with \code{NA}'s.}
   \item{'wij'} {A sparse [N,N] matrix where each cell represents \eqn{w_{ij}}.}
   \item{'call'}
   \item{'coords'} {A [N,D] matrix of the embedding of the dataset in the low-dimensional space.}
 }
}
\description{
Implements the \code{largeVis} algorithm by Tang et al.
}
\details{
\code{largeVis} estimates a low-dimensional embedding for high-dimensional data, where the distance between vertices
in the low-dimensional space is proportional to the distance between them in the high-dimensional space. The algorithm
works in 4 phases:

\itemize{
\item  Estimate candidate nearest-neighbors for each vertex by building \code{n.trees} random projection trees.
\item  Estimate \code{K} nearest-neighbors for each vertex by visiting each vertex' 2d-degree neighbors (its neighbors' neighbors).
This is repeated \code{max.iter} times.  Note that the original paper suggested a \code{max.iter} of 1, however a larger number
may be appropriate for some datasets if the algorithm has trouble finding K neighbors for every vertex.
\item Estimate \eqn{p_{j|i}}, the conditional probability that each edge found in the previous step is actually to a
nearest neighbor of each of its nodes.
\item Using stochastic gradient descent, estimate an embedding for each vertex in the low-dimensional space.
}

Note that this implementation expects the data to be free of \code{NaN}'s, \code{NA}'s, \code{Inf}'s, and duplicate rows.
If any of these assumptions are violated, the algorithm will fail. It is also usually a good idea to sale the input data
to have unit norm and mean 0. If there are large values in the input matrix, some computations may oveflow.
}
\examples{
data(iris)
dat <- as.matrix(iris[,1:4])
dat <- scale(dat)
dupes = which(duplicated(dat))
dat <- dat[-dupes,] # duplicated data potentially can cause the algorithm to fail
visObject <- largeVis(dat, pca.first = F,
                     max.iter = 20, sgd.batches = 800000,
                     K = 10,  gamma = 2, rho = 1, M = 40, alpha = 20,verbose=F)

 load("./mnist.Rda")
 dat <- mnist$images
 dim(dat) <- c(42000, 28 * 28)
 dat <- (dat / 255) - 0.5
 coords <- largeVis(dat, pca.f = F,
                  n.tree = 10, tree.th = 40,
                  K = 40, sgd = 20000 * 42000, alpha = 1, max.iter = 10)

}
\references{
Jian Tang, Jingzhou Liu, Ming Zhang, Qiaozhu Mei. \href{https://arxiv.org/abs/1602.00370}{Visualizing Large-scale and High-dimensional Data.}
}

